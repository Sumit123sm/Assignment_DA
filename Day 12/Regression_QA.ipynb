{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4aea84f",
   "metadata": {},
   "source": [
    "## Polynomial and Linear Regression Q&A\n",
    "This notebook contains a collection of questions and answers related to regression analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812931ea",
   "metadata": {},
   "source": [
    "### What is Simple Linear Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21767688",
   "metadata": {},
   "source": [
    "Simple Linear Regression is a statistical method used to model the relationship between a dependent variable and a single independent variable using a linear equation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e451af",
   "metadata": {},
   "source": [
    "### What are the key assumptions of Simple Linear Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2441c249",
   "metadata": {},
   "source": [
    "The key assumptions include linearity, independence of errors, homoscedasticity, normality of residuals, and no multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c09309e",
   "metadata": {},
   "source": [
    "### What does the coefficient m represent in the equation Y=mx+c?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f945caf5",
   "metadata": {},
   "source": [
    "The coefficient 'm' represents the slope, indicating the change in the dependent variable for a one-unit change in the independent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c76193a",
   "metadata": {},
   "source": [
    "### What does the intercept c represent in the equation Y=mx+c?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b896c695",
   "metadata": {},
   "source": [
    "The intercept 'c' represents the value of the dependent variable when the independent variable is zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daed7631",
   "metadata": {},
   "source": [
    "### How do we calculate the slope m in Simple Linear Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ff0fdb",
   "metadata": {},
   "source": [
    "The slope is calculated using the formula: m = (Σ(xi - x̄)(yi - ȳ)) / (Σ(xi - x̄)²)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5226add2",
   "metadata": {},
   "source": [
    "### What is the purpose of the least squares method in Simple Linear Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c986e4cf",
   "metadata": {},
   "source": [
    "The least squares method minimizes the sum of the squared differences between observed and predicted values to find the best-fitting line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6970fdf",
   "metadata": {},
   "source": [
    "### How is the coefficient of determination (R²) interpreted in Simple Linear Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa1aa0b",
   "metadata": {},
   "source": [
    "R² measures the proportion of variance in the dependent variable explained by the independent variable. A higher R² indicates a better fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e036fd81",
   "metadata": {},
   "source": [
    "### What is Multiple Linear Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb991c5c",
   "metadata": {},
   "source": [
    "Multiple Linear Regression is an extension of Simple Linear Regression where multiple independent variables predict a dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568465ea",
   "metadata": {},
   "source": [
    "### What is the main difference between Simple and Multiple Linear Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cbf3b2",
   "metadata": {},
   "source": [
    "Simple Linear Regression uses one independent variable, whereas Multiple Linear Regression uses two or more independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc44d84",
   "metadata": {},
   "source": [
    "### What are the key assumptions of Multiple Linear Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709e381b",
   "metadata": {},
   "source": [
    "The assumptions include linearity, independence, homoscedasticity, normality of residuals, and no multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4429dc",
   "metadata": {},
   "source": [
    "### What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c24c16",
   "metadata": {},
   "source": [
    "Heteroscedasticity refers to non-constant variance in residuals, leading to unreliable standard errors and inefficient estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0ee390",
   "metadata": {},
   "source": [
    "### How can you improve a Multiple Linear Regression model with high multicollinearity?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac3b77b",
   "metadata": {},
   "source": [
    "Techniques include removing correlated variables, using Principal Component Analysis (PCA), or applying Ridge/Lasso regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e4617e",
   "metadata": {},
   "source": [
    "### What are some common techniques for transforming categorical variables for use in regression models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbf151a",
   "metadata": {},
   "source": [
    "Techniques include one-hot encoding, label encoding, and ordinal encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bad34ae",
   "metadata": {},
   "source": [
    "### What is the role of interaction terms in Multiple Linear Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec3ee6f",
   "metadata": {},
   "source": [
    "Interaction terms capture the combined effect of two or more independent variables on the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8921a9e",
   "metadata": {},
   "source": [
    "### How can the interpretation of intercept differ between Simple and Multiple Linear Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde42083",
   "metadata": {},
   "source": [
    "In Simple Linear Regression, the intercept represents the predicted value when x=0. In Multiple Linear Regression, it represents the predicted value when all independent variables are zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731616ba",
   "metadata": {},
   "source": [
    "### What is the significance of the slope in regression analysis, and how does it affect predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a21b4bc",
   "metadata": {},
   "source": [
    "The slope indicates the strength and direction of the relationship between the independent and dependent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee2810f",
   "metadata": {},
   "source": [
    "### How does the intercept in a regression model provide context for the relationship between variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa75c2e",
   "metadata": {},
   "source": [
    "The intercept provides a baseline value for the dependent variable when independent variables are zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae7e781",
   "metadata": {},
   "source": [
    "### What are the limitations of using R² as a sole measure of model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082ba13b",
   "metadata": {},
   "source": [
    "R² does not indicate causality, is sensitive to outliers, and does not assess model complexity or overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8706fc9e",
   "metadata": {},
   "source": [
    "### How would you interpret a large standard error for a regression coefficient?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cd2b9d",
   "metadata": {},
   "source": [
    "A large standard error suggests variability in coefficient estimates, implying low reliability in predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3678271d",
   "metadata": {},
   "source": [
    "### How can heteroscedasticity be identified in residual plots, and why is it important to address it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa82339",
   "metadata": {},
   "source": [
    "Heteroscedasticity is identified when residuals exhibit a funnel-like pattern in plots. Addressing it ensures valid statistical inferences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36986e69",
   "metadata": {},
   "source": [
    "### What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907c96b5",
   "metadata": {},
   "source": [
    "It indicates that additional independent variables do not significantly contribute to explaining the variance in the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e87d3c4",
   "metadata": {},
   "source": [
    "### Why is it important to scale variables in Multiple Linear Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6683a3a1",
   "metadata": {},
   "source": [
    "Scaling ensures that variables with different units or ranges contribute equally, preventing biased coefficient estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a679642a",
   "metadata": {},
   "source": [
    "### What is polynomial regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf4e1ab",
   "metadata": {},
   "source": [
    "Polynomial regression is a type of regression analysis that models the relationship between the dependent and independent variable as an nth-degree polynomial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c2c525",
   "metadata": {},
   "source": [
    "### How does polynomial regression differ from linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31dc995",
   "metadata": {},
   "source": [
    "Polynomial regression captures nonlinear relationships by introducing polynomial terms of the independent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c96fba2",
   "metadata": {},
   "source": [
    "### When is polynomial regression used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca31282",
   "metadata": {},
   "source": [
    "Polynomial regression is used when the relationship between variables is nonlinear but can be approximated using polynomial functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a5c3f6",
   "metadata": {},
   "source": [
    "### What is the general equation for polynomial regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d1ea0b",
   "metadata": {},
   "source": [
    "The general equation is Y = b0 + b1X + b2X² + ... + bnX^n."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acce33a5",
   "metadata": {},
   "source": [
    "### Can polynomial regression be applied to multiple variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d1ad8f",
   "metadata": {},
   "source": [
    "Yes, polynomial regression can be extended to multiple variables, creating interaction and higher-order terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeee6a1",
   "metadata": {},
   "source": [
    "### What are the limitations of polynomial regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7fa94d",
   "metadata": {},
   "source": [
    "Limitations include overfitting, high sensitivity to outliers, and difficulty in interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b78e76",
   "metadata": {},
   "source": [
    "### What methods can be used to evaluate model fit when selecting the degree of a polynomial?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8177d7e3",
   "metadata": {},
   "source": [
    "Methods include cross-validation, adjusted R², and Akaike Information Criterion (AIC)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be3602f",
   "metadata": {},
   "source": [
    "### Why is visualization important in polynomial regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6274f92d",
   "metadata": {},
   "source": [
    "Visualization helps in understanding the fit of the model and detecting underfitting or overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eacec90",
   "metadata": {},
   "source": [
    "### How is polynomial regression implemented in Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105e3b3d",
   "metadata": {},
   "source": [
    "Polynomial regression is implemented using `PolynomialFeatures` from scikit-learn, followed by linear regression on the transformed features."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}